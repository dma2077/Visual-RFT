#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import json
import os
import time
from concurrent.futures import ThreadPoolExecutor
from datasets import Dataset, DatasetDict, Features, Value, Image
from tqdm import tqdm

def parse_args():
    parser = argparse.ArgumentParser(
        description='åŸºäº food101_question.json æ„é€  few-shot HF Dataset'
    )
    parser.add_argument(
        '--json', type=str,
        default='/llm_reco/dehua/data/questions/foodx251_question.json',
        help='åŸå§‹ JSON æ–‡ä»¶è·¯å¾„ï¼ˆå« images & conversationsï¼‰'
    )
    parser.add_argument(
        '--k', type=int, default=10000,
        help='æ¯ä¸ªç±»åˆ«ä¿ç•™å‰ K æ¡æ ·æœ¬'
    )
    parser.add_argument(
        '--workers', type=int, default=64,
        help='å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°'
    )
    parser.add_argument(
        '--output_path', type=str,
        default='/llm_reco/dehua/code/Visual-RFT/share_data/food251_all_dataset_nocot',
        help='è¾“å‡º HF DatasetDict è·¯å¾„ï¼Œæ¨èä½¿ç”¨ç»å¯¹è·¯å¾„'
    )
    return parser.parse_args()

def load_raw(json_path):
    with open(json_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def select_k_shot(data, k_shot):
    selected, counts = [], {}
    for d in data:
        cat = d['conversations'][1]['value']
        if counts.get(cat, 0) >= k_shot:
            continue
        counts[cat] = counts.get(cat, 0) + 1
        selected.append(d)
    print(f"â–  åŸå§‹å…± {len(data)} æ¡ï¼Œfew-shot å {len(selected)} æ¡ï¼›å„ç±»åˆ†å¸ƒï¼š{counts}")
    return selected

def process_image_path(d):
    raw = d["images"][0]
    image_path = raw.replace(
        "/map-vepfs/dehua/data/data/",
        "/llm_reco/dehua/data/food_data/"
    )

    # æ£€æŸ¥å¹¶ç¡®ä¿ image_path å­˜åœ¨
    if not os.path.exists(image_path):
        print(f"âš ï¸ Warning: Image path ä¸å­˜åœ¨ - {image_path}")

    sol_txt = d['conversations'][1]['value']

    # å¼ºåˆ¶sol_txtä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…ç±»å‹æ··åˆ
    if isinstance(sol_txt, list):
        sol_txt = " ".join(sol_txt)
        print(sol_txt)
    elif sol_txt is None or not isinstance(sol_txt, str):
        sol_txt = ""
        print("None")
    sol_txt = sol_txt.strip()  # å»é™¤å‰åç©ºæ ¼

    return {
        'image_path': image_path,
        'problem': "<image>\nWhat is the category of the food?",
        'solution': f"<answer>{sol_txt}</answer>",
        'category': sol_txt
    }

def build_dataset_dict(records, save_path):
    image_paths = [r['image_path'] for r in records]
    problems    = [r['problem']    for r in records]
    solutions   = [r['solution']   for r in records]
    categories  = [r['category']   for r in records]

    features = Features({
        'image':    Image(),
        'problem':  Value('string'),
        'solution': Value('string'),
        'category': Value('string')
    })

    ds = Dataset.from_dict(
        {
            'image':    image_paths,
            'problem':  problems,
            'solution': solutions,
            'category': categories
        },
        features=features
    )

    ds_dict = DatasetDict({'train': ds})

    # å®‰å…¨å†™å…¥æ–‡ä»¶å¹¶æ•è·å¼‚å¸¸
    try:
        ds_dict.save_to_disk(save_path)
        print(f"âœ… DatasetDict å·²ä¿å­˜åˆ° {save_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜DatasetDictå¤±è´¥ï¼š{e}")

    return ds_dict

def main():
    args = parse_args()
    print("ğŸš© è„šæœ¬å¼€å§‹ï¼š", time.asctime())

    raw = load_raw(args.json)
    sel = select_k_shot(raw, args.k)

    print("ğŸš© å¹¶è¡Œå¤„ç†è·¯å¾„ä¸æ–‡æœ¬â€¦")
    with ThreadPoolExecutor(max_workers=args.workers) as exe:
        records = list(tqdm(
            exe.map(process_image_path, sel),
            total=len(sel),
            desc="å¤„ç†æ•°æ®",
            unit="æ¡"
        ))

    def check_records(records):
        for idx, record in enumerate(records):
            for key, value in record.items():
                if not isinstance(value, str):
                    print(f"[ç±»å‹é—®é¢˜] åœ¨ç¬¬ {idx} æ¡æ•°æ®ï¼Œå­—æ®µ '{key}' ä¸æ˜¯å­—ç¬¦ä¸²ï¼Œå®é™…å€¼: {value}ï¼Œç±»å‹: {type(value)}", flush=True)
    print("ğŸ” æ£€æŸ¥è®°å½•å­—æ®µç±»å‹...", flush=True)
    check_records(records)
    # æ„é€ å¹¶ä¿å­˜ HF DatasetDict
    ds_dict = build_dataset_dict(records, args.output_path)

    print("ğŸš© è„šæœ¬ç»“æŸï¼š", time.asctime())
    # ç¤ºä¾‹åŠ è½½æ•°æ®:
    # from datasets import DatasetDict
    # loaded = DatasetDict.load_from_disk(args.output_path)

if __name__ == '__main__':
    main()
